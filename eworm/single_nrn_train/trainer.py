"""
Functions work for:
    1. single neuron dataset, extract data from pickle file generated by datamaker
    2. data normalize and transform between different data form
    3. main train process and related functions
    4. test process (single neuron connection weight infer)
"""
import os
import glob
import torch
import torch.nn as nn
from eworm.single_nrn_train.model import *
import numpy as np
from tqdm import tqdm
import os.path as path
import _pickle as pickle
from torch.utils.data import Dataset, DataLoader
from eworm.utils import *
from eworm.network import *


class SingleNeuronDataset(Dataset):
    def __init__(self, cell_name, dataset_dir, squeeze, noise, test=False):
        super(SingleNeuronDataset, self).__init__()
        data_pkl_list = sorted(glob.glob(path.join(dataset_dir, cell_name, cell_name + "*.dat")))
        self.pkl_list = data_pkl_list[:1] if test else data_pkl_list[1:]
        data_sample = pickle.load(open(self.pkl_list[0], 'rb'))
        input_shape = data_factory.squeeze_trace(np.zeros(data_sample['input_traces'].shape), squeeze).shape
        output_shape = data_factory.squeeze_trace(np.zeros(data_sample['output_traces'].shape), squeeze).shape
        self.trace_len, self.noise = input_shape[-1], noise
        connect_shape = data_sample['connection_weights'].shape
        self.input_traces = np.zeros((len(self.pkl_list) * input_shape[0], *input_shape[1:]))
        self.output_traces = np.zeros((len(self.pkl_list) * output_shape[0], *output_shape[1:]))
        self.connect_weights = np.zeros((len(self.pkl_list) * connect_shape[0], *connect_shape[1:]))

        for file_index, sample_file in enumerate(self.pkl_list):
            print('loading ' + sample_file)
            data = pickle.load(open(sample_file, 'rb'))
            self.input_traces[file_index * input_shape[0]: (file_index + 1) * input_shape[0]] = \
                data_factory.squeeze_trace(data['input_traces'], squeeze)
            self.output_traces[file_index * output_shape[0]: (file_index + 1) * output_shape[0]] = \
                data_factory.squeeze_trace(data['output_traces'], squeeze)
            self.connect_weights[file_index * connect_shape[0]: (file_index + 1) * connect_shape[0]] = \
                data['connection_weights']
        self.input_traces = torch.tensor(self.input_traces, dtype=torch.float32)
        self.output_traces = torch.tensor(self.output_traces, dtype=torch.float32)
        self.connect_weights = torch.tensor(self.connect_weights, dtype=torch.float32)

    def __getitem__(self, index):
        in_noise = torch.randn(self.input_traces[index].shape) * self.noise
        # out_noise = torch.randn(self.output_traces[index].shape)
        return {
            'input_traces': self.input_traces[index] + in_noise,
            'output_traces': self.output_traces[index],  # + out_noise,
            'connection_weights': self.connect_weights[index]
        }

    def __len__(self):
        return len(self.input_traces)


def ckp_mini(infer_batch, model, categories, weight_config, device, save_dir):
    infer_input = infer_batch["input_traces"].to(device).unsqueeze(0)
    infer_weights = data_factory.sample2input(infer_batch["connection_weights"].unsqueeze(0), categories,
                                              weight_config).to(device)
    infer_prediction = model((infer_input + 25) / 75, infer_weights)[0] * 75 - 25
    infer_prediction = infer_prediction[0].cpu().numpy()  # * 0.5 + infer_batch["output_traces"].cpu().numpy() * 0.5
    prefix_init = infer_batch["output_traces"].cpu().numpy()[..., 0:1]
    infer_prediction = np.concatenate([prefix_init, infer_prediction[..., :-1]], axis=-1)
    vis.visualize_train_ckp(infer_batch["input_traces"].cpu().numpy(), infer_batch["output_traces"].cpu().numpy(),
                            infer_prediction, infer_batch["connection_weights"].cpu().numpy(), categories, save_dir)


def train(cell, train_config, model_config, save_dir):
    """
    main training function

    Args:
        cell: reference cell
        train_config: config dictionary for training and dataloader
            batch_size
            n_cpu
            num_epoch
            lr
            window_size
            squeeze
            dataset_dir
            device
            weight_config
            loss_thresh
            loss_type
            noise
            validation
        model_config:
            model_name
            pretrain_dir
            args
                ...
                ...
        save_dir: checkpoint saving directory
    """
    assert isinstance(cell, (abstract_circuit.AbsCell, detailed_circuit.Cell))
    torch.backends.cudnn.benchmark = True
    device = torch.device(train_config['device'])
    train_dataset = SingleNeuronDataset(cell.name, train_config['dataset_dir'], train_config['squeeze'],
                                        noise=train_config["noise"], test=False)
    test_dataset = SingleNeuronDataset(cell.name, train_config['dataset_dir'], train_config['squeeze'],
                                       noise=train_config["noise"], test=True)
    train_dataloader = DataLoader(train_dataset, batch_size=train_config['batch_size'], shuffle=True,
                                  num_workers=train_config["n_cpu"])
    trace_len, half_window = train_dataset.trace_len, int(train_config['window_size'] // 2)
    print(trace_len, half_window)
    window_num = int(np.ceil(trace_len / half_window)) - 1
    if not train_config["validation"]:
        working_directory = path.join(save_dir, cell.name, 'train')
    else:
        working_directory = path.join(save_dir, cell.name, 'valid')
    os.makedirs(working_directory, exist_ok=True)
    # make model
    model = eval(model_config['model_name'])(**model_config['args']).to(device)
    if model_config['pretrain_dir'] is not None:
        print(f"loading pretrained checkpoint from {model_config['pretrain_dir']}")
        model_ckp_list = sorted(glob.glob(path.join(model_config['pretrain_dir'], cell.name, 'train', 'model_*.ckp')),
                                key=lambda x: int(x.split('model_epoch#')[-1].split('.ckp')[0]))
        model.load_state_dict(torch.load(model_ckp_list[-1], map_location=device))
    optimizer = torch.optim.Adam(model.parameters(), lr=train_config['lr'])
    criterion = nn.L1Loss().to(device) if train_config["loss_type"] == "L1" else nn.MSELoss().to(device)
    connection_categories = [connection.category for connection in cell.pre_connections]
    loss_rec, loss_mean_rec = [], []
    # train process
    for epoch in range(train_config['num_epoch']):
        for batch in tqdm(train_dataloader, mininterval=10):
            input_traces, output_traces = batch["input_traces"].to(device), batch["output_traces"].to(device)
            connection_weights = data_factory.sample2input(batch["connection_weights"], connection_categories,
                                                           train_config['weight_config']).to(device)
            if train_config['validation']:
                connection_weights = torch.randn(connection_weights.shape).to(device)
            input_traces = (input_traces + 25) / 75
            inter_ckp = None
            for window_idx in range(window_num):
                input_trace1 = input_traces[..., window_idx * half_window:(window_idx + 1) * half_window]
                input_trace2 = input_traces[..., (window_idx + 1) * half_window:(window_idx + 2) * half_window]
                output_trace = output_traces[..., window_idx * half_window:(window_idx + 2) * half_window]
                prediction1, inter_ckp = model(input_trace1, connection_weights, init=inter_ckp)
                prediction2, _ = model(input_trace2, connection_weights, init=inter_ckp)
                prediction = torch.cat((prediction1, prediction2), dim=-1)
                loss = criterion((prediction[..., :-1] * 75 - 25),  # * 0.5 + output_trace[..., :-1] * 0.5,
                                 output_trace[..., 1:])
                optimizer.zero_grad()
                loss.backward()
                optimizer.step()
                inter_ckp.detach_()
                loss_rec.append(float(loss))
                loss_mean_rec.append(np.mean(loss_rec[-100:]))
        # checkpoint
        if epoch & (epoch - 1) == 0:
            with torch.no_grad():
                for data_idx in (0, 1, 2):
                    ckp_mini(train_dataset[data_idx], model, connection_categories, train_config['weight_config'],
                             device, path.join(working_directory, f"train_epoch#{epoch}_{data_idx}.jpg"))
                    ckp_mini(test_dataset[data_idx], model, connection_categories, train_config['weight_config'],
                             device, path.join(working_directory, f"test_epoch#{epoch}_{data_idx}.jpg"))
                torch.save(model.state_dict(), path.join(working_directory, f"model_epoch#{epoch}.ckp"))
            vis.visualize_loss(loss_rec, loss_mean_rec, path.join(working_directory, "loss.jpg"))
            print(len(loss_mean_rec))
            if (loss_mean_rec[int(len(loss_mean_rec) / 2)] / loss_mean_rec[-1] < np.exp(
                    train_config['loss_thresh'])) and (epoch > 4):
                return epoch
    return train_config['num_epoch'] - 1
